---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/postgresql.cnpg.io/cluster_v1.json
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: pgvectors
spec:
  instances: 3
  imageName: ghcr.io/tensorchord/cloudnative-pgvecto.rs:16.2-v0.2.1
  primaryUpdateStrategy: unsupervised
  storage:
    size: 10Gi
    storageClass: truenas-ssd-iscsi
  superuserSecret:
    name: cloudnative-pg
  enableSuperuserAccess: true
  postgresql:
    shared_preload_libraries:
      - "vectors.so"
    parameters:
      max_connections: "600"
      shared_buffers: 512MB
      # https://github.com/tensorchord/cloudnative-pgvecto.rs/issues/29
      search_path: '"$user", public, vectors'
  nodeMaintenanceWindow:
    inProgress: false
    reusePVC: true
  resources:
    requests:
      cpu: 500m
      memory: 2Gi
    limits:
      memory: 4Gi
  monitoring:
    enablePodMonitor: true
  backup:
    retentionPolicy: 30d
    barmanObjectStore: &barmanObjectStore
      data:
        compression: bzip2
      wal:
        compression: bzip2
        maxParallel: 8
      destinationPath: s3://cloudnative-pg/
      endpointURL: https://s3.${SECRET_DOMAIN}
      # Note: serverName version needs to be incremented when recovering from
      # an existing CloudNativePG cluster.
      serverName: &currentCluster pgvectors-v2
      s3Credentials:
        accessKeyId:
          name: cloudnative-pg
          key: s3-access-key
        secretAccessKey:
          name: cloudnative-pg
          key: s3-secret-key
  # Note: previousCluster needs to be set to the name of the previous cluster
  # when recovering from an existing CloudNativePG cluster.
  # bootstrap:
  #   recovery:
  #     source: &previousCluster pgvectors-v1
  # Note: externalClusters is needed when recovering from an existing
  # CloudNativePG cluster.
  # externalClusters:
  #   - name: *previousCluster
  #     barmanObjectStore:
  #       <<: *barmanObjectStore
  #       serverName: *previousCluster
